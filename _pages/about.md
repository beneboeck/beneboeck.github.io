---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About Me
======
I am a research assistant and doctoral candidate at the Chair of Signal Processing, Technical University of Munich, under the supervision of Prof. Wolfgang Utschick. I obtained a B.Sc. (2019) and M.Sc. (2022) in Electrical Engineering and Information Technology from the Technical University of Munich (TUM), and a B.Sc. (2020) in Physics from (Ludwig Maximilian University) LMU Munich.

Research Interests
======
I am broadly interested in Statistical Machine Learning and Signal Processing as well as Wireless Communications. I am currently working on two topics from which one is very specific for Wireless Communications and the other targets general machine learning:


**Combining the Physics of Wireless Signals with Machine Learning for Physical Layer Applications**

The challenges of applying machine learning, particularly deep learning, in wireless communications are mainly due to the difficulty of acquiring clean training data, the vast amount of system configurations resulting in varying data representations, and the strict latency and computational constraints. In my research, I try to address these issues by leveraging model knowledge—especially the underlying laws of physics—for designing trainable models and algorithms. For more details, see [our recent ICML25 paper]({{ site.baseurl }}/publication/physics_informed).

---

**Exploiting Structural Prior Knowledge about the Data to Facilitate Learning and Improve Performance in Generative Modeling**

Probabilistic priors have been used as regularizers long before modern generative models emerged. Traditionally, such priors were not trainable but encoded domain-specific expert knowledge about the data (e.g., sparsity). In contrast, modern generative models are generally not designed to incorporate this type of prior knowledge. In my research, I investigate how expert knowledge can be integrated into the design of generative models to facilitate learning and enhance performance across various applications. For more details, see [our recent NeurIPS24 paper]({{ site.baseurl }}/publication/sbgm).
